---
- name: Scale Moodle for 10k Concurrent Users
  hosts: localhost
  connection: local
  gather_facts: false

  vars:
    moodle_namespace: moodle
    moodle_release_name: moodle
    target_replicas: 3
    php_fpm_config:
      pm_type: static
      max_children: 200
      start_servers: 50
      min_spare_servers: 50
      max_spare_servers: 100
      max_requests: 500
    moodle_resources:
      requests:
        cpu: "2000m"
        memory: "6Gi"
      limits:
        cpu: "4000m"
        memory: "8Gi"

  tasks:
    - name: Display scaling plan
      debug:
        msg: |
          Scaling Moodle deployment for 10k concurrent users:
          - Increasing replicas from 3 to {{ target_replicas }}
          - Updating PHP-FPM max_children from 50 to {{ php_fpm_config.max_children }}
          - Adjusting resource allocation per pod
          - Total capacity: {{ target_replicas }} pods × {{ php_fpm_config.max_children }} processes = {{ target_replicas * php_fpm_config.max_children }} concurrent requests

    - name: Add Bitnami Helm repository
      command: helm repo add bitnami https://charts.bitnami.com/bitnami
      register: helm_repo_result
      failed_when: helm_repo_result.rc != 0 and 'already exists' not in helm_repo_result.stderr

    - name: Update Helm repositories
      command: helm repo update

    - name: Deploy single Moodle pod first for database initialization
      kubernetes.core.k8s:
        definition:
          apiVersion: apps/v1
          kind: Deployment
          metadata:
            name: moodle
            namespace: "{{ moodle_namespace }}"
            labels:
              app.kubernetes.io/name: moodle
              app.kubernetes.io/instance: moodle
          spec:
            replicas: 1
            selector:
              matchLabels:
                app.kubernetes.io/name: moodle
                app.kubernetes.io/instance: moodle
            template:
              metadata:
                labels:
                  app.kubernetes.io/name: moodle
                  app.kubernetes.io/instance: moodle
              spec:
                containers:
                - name: moodle
                  image: aragawmebratu/moodle-with-tools:latest
                  ports:
                  - containerPort: 8080
                    name: http
                  - containerPort: 8443
                    name: https
                  env:
                  - name: BITNAMI_DEBUG
                    value: "false"
                  - name: ALLOW_EMPTY_PASSWORD
                    value: "yes"
                  - name: APACHE_HTTP_PORT_NUMBER
                    value: "8080"
                  - name: APACHE_HTTPS_PORT_NUMBER
                    value: "8443"
                  - name: MOODLE_DATABASE_TYPE
                    value: pgsql
                  - name: MOODLE_DATABASE_HOST
                    value: moodle-db-cluster-pooler.database.svc.cluster.local
                  - name: MOODLE_DATABASE_PORT_NUMBER
                    value: "5432"
                  - name: MOODLE_DATABASE_NAME
                    value: moodledb
                  - name: MOODLE_DATABASE_USER
                    value: moodleuser
                  - name: MOODLE_DATABASE_PASSWORD
                    value: PQl5YR30j9geR9NrgLTPxzTBkNZ2OYIDDiLaDZm946Nk7O1mWmPsArY5C7yj9vcw
                  - name: MOODLE_SKIP_BOOTSTRAP
                    value: "yes"
                  - name: MOODLE_USERNAME
                    value: admin
                  - name: MOODLE_PASSWORD
                    value: admin123
                  - name: MOODLE_EMAIL
                    value: admin@example.com
                volumeMounts:
                - name: config
                  mountPath: /bitnami/moodle/config.php
                  subPath: config.php
                  readOnly: true
                - name: moodle-data
                  mountPath: /bitnami/moodle
                  subPath: moodle
                - name: moodle-data
                  mountPath: /bitnami/moodledata
                  subPath: moodledata
              volumes:
              - name: config
                configMap:
                  name: config
              - name: moodle-data
                persistentVolumeClaim:
                  claimName: moodle-moodle
        wait: yes
        wait_sleep: 10
        wait_timeout: 300

    # NOTE: Skipping the single pod wait as requested

    - name: Scale Moodle deployment to full capacity
      kubernetes.core.k8s_scale:
        api_version: apps/v1
        kind: Deployment
        name: moodle
        namespace: "{{ moodle_namespace }}"
        replicas: "{{ target_replicas }}"
        wait: yes
        wait_sleep: 10
        wait_timeout: 600

    - name: Wait for deployment to be ready
      kubernetes.core.k8s_info:
        kind: Deployment
        name: moodle
        namespace: "{{ moodle_namespace }}"
      register: deployment_status
      until: >
        deployment_status.resources is defined and
        deployment_status.resources | length > 0 and
        deployment_status.resources[0].status.availableReplicas is defined and
        deployment_status.resources[0].status.availableReplicas >= target_replicas
      retries: 30
      delay: 30

    - name: Verify scaled deployment
      debug:
        msg: |
          Moodle deployment successfully scaled:
          - Running {{ target_replicas }} pods
          - Each pod configured with {{ php_fpm_config.max_children }} PHP-FPM processes
          - Total capacity: {{ target_replicas * php_fpm_config.max_children }} concurrent requests
          - Resource allocation: {{ moodle_resources.requests.cpu }} CPU, {{ moodle_resources.requests.memory }} memory per pod

    - name: Update K6 test configuration
      copy:
        content: |
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { SharedArray } from 'k6/data';

          export const options = {
            vus: 500,
            duration: '5m',
            thresholds: {
              http_req_failed: ['rate<0.05'],
              http_req_duration: ['p(95)<3000'],
            },
          };

          const users = new SharedArray('users', function () {
            return open('/home/administrator/k6/moodle/datasets/moodle_users_1000.csv')
              .split('\n')
              .slice(1)
              .filter(l => l.trim() !== '')
              .map(line => {
                const [username, password] = line.split(',');
                return { username, password };
              });
          });

          export default function () {
            const user = users[__VU % users.length];

            // 1. Load login page
            const loginPage = http.get('http://10.139.8.131:32752/login/index.php');

            const logintoken = loginPage
              .html()
              .find('input[name=logintoken]')
              .val();

            check(logintoken, {
              'logintoken found': t => t !== undefined,
            });

            // 2. Submit login form
            const res = http.post(
              'http://10.139.8.131:32752/login/index.php',
              {
                username: user.username,
                password: user.password,
                logintoken: logintoken,
              },
              { redirects: 0 }
            );

            check(res, {
              'login success': r => r.status === 302 || r.status === 303,
            });

            sleep(1);
          }
        dest: /opt/k6/moodle/login-highload.js
        mode: '0644'

    - name: Success message
      debug:
        msg: |
          ✅ Moodle successfully scaled for 10k concurrent users!
          
          Next steps:
          1. Run the updated K6 test: k6 run /opt/k6/moodle/login-highload.js
          2. Monitor pod resource usage: kubectl top pods -n moodle
          3. Check application logs: kubectl logs -n moodle -l app.kubernetes.io/name=moodle
          
          Expected capacity:
          - 20 pods × 200 PHP processes = 4000 concurrent requests
          - With proper load balancing, this can handle 10k concurrent users
          - Monitor and adjust based on actual performance metrics